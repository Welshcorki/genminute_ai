제1차 회의 – STT 모델 선정 및 테스트 기준 설정 (자연 대화 리듬 버전)
세아: 자, 오늘은 STT 모델 후보를 정리하고 테스트 기준을 세워보죠. 지금 후보는 Whisper, 클로바스피치, 제미나이 세 가지예요.
정현: 그럼 테스트 데이터부터 잡을까요? 회의형, 뉴스형, 일상대화형으로 나누면 모델별 특성 보기가 좋을 것 같아요.
세아: 음, 그 구분 괜찮아요. 실제 회의에선 잡음이 섞이니까 ‘회의형’ 데이터를 중점적으로 써보면 좋겠네요.
용훈: 맞아요. Whisper는 잡음엔 강한 편이지만 속도가 느리고, 클로바는 한글엔 강하지만 긴 문장 처리가 불안정하더라고요.
제미나이는 전체적으로 밸런스는 좋은데 비용이 좀 걸리죠.
세아: 결국 다 장단이 있네요. 그럼 세 모델 다 돌려서 결과를 보고 판단하죠.
수현: 그럼 DB 스키마부터 잡아둘게요. 파일 경로, 화자 수, 길이, 주제, 환경 같은 필드 넣어서 테스트 결과랑 매칭되게요.
정현: 아, 그러면 나중에 각 모델 결과를 바로 비교할 수 있겠네요. 그래프 그리기도 쉽고.
용훈: 맞아요. CER 중심으로 비교하되, 처리 속도랑 API 비용도 같이 기록해요. 실제 서비스할 때는 그게 중요하니까요.
세아: 그러면 이번 테스트의 목적은 단순히 “어떤 모델이 더 정확한가”가 아니라, “우리 환경에서 가장 효율적인 모델은 무엇인가”로 잡죠.그래야 단순 수치보다 실제 적용 가능성을 보여줄 수 있잖아요.결국엔 우리 프로젝트에 들어갈 STT 엔진 선택이 목표니까, 그 방향으로 진행해요.
용훈: 네, 방향 좋네요. 그럼 Whisper 세팅은 제가 맡을게요. PyTorch 환경 세팅하고 기본 파이프라인 돌려볼게요.
정현: 클로바랑 제미나이는 제가 API 연결 테스트하겠습니다. 호출 한도나 응답 속도 체크까지 같이요.
수현: 저장은 SQLite로 갈게요. 결과 테이블은 run_id 단위로 묶어서 회차별 비교가 가능하게 할게요.
세아: 완벽해요.
정현: 아, 데이터 길이는 최소 10분 이상으로 통일할까요? 너무 짧으면 비교가 어렵겠어요.
용훈: 10분 좋네요. 대신 잡음 섞인 버전 하나, 깨끗한 버전 하나로 나눠서 비교하면 더 명확하죠.
수현: 그럼 DB에 환경 필드 넣을게요. 예: ‘회의실’, ‘카페’, ‘온라인 통화’ 이런 식으로요.
세아: 좋네요. 현실적인 조건이라 더 설득력 있을 거예요.
용훈: 세아님, 제가 보고서 생각해봤는데요. 단순 표보다는 흐름형 다이어그램 하나 넣으면 어떨까요?예를 들어 “오디오 입력 → 전처리 → STT → 결과 저장” 이렇게 단계별로 보여주면, 기술적인 디테일을 몰라도 전체 구조가 눈에 들어올 거예요.특히 발표 때 ‘아, 이런 구조로 인식이 이루어지는구나’ 하고 청중이 바로 이해할 수 있을 겁니다.
세아: 와, 그거 좋다. 발표용으로 완벽하네요. 그럼 제가 PPT에 그래프랑 같이 배치해볼게요.
정현: 저도 테스트 자동화 스크립트 거기에 맞춰 짜볼게요. 결과를 한 번에 볼 수 있게요.
수현: 저는 대시보드 기초 뷰를 만들어볼게요. 테이블 대신 시각적으로 성능을 비교할 수 있도록요.
세아: 그럼 다들 완전 준비됐네요. 일정은 이번 주 수·목 테스트, 금요일 중간 공유로 할게요.
용훈: 네, Whisper 환경은 오늘 바로 세팅 들어갑니다.
정현: 제미나이 쪽은 API 키 발급 확인 후 바로 돌려볼게요.
수현: .env 분리도 마무리해둘게요. 보안 변수는 전부 마스킹 처리하겠습니다.
세아: 너무 좋아요. 다음 회의에서 각자 결과 공유하면 바로 비교 들어갈 수 있겠네요.
정현: 네, 그때는 모델별로 성능 차이 좀 나올 거예요. 흥미롭겠네요.
용훈: 그럼 각자 맡은 부분 정리해서 공유드릴게요.
수현: DB 스키마도 오늘 안에 업데이트해둘게요.
세아: 좋아요, 여러분. 오늘 회의 분위기 최고네요. 다음엔 결과 보면서 좀 더 구체적으로 논의합시다.
정현: 네, 오늘은 평화로운 1차 회의였어요. 다음엔 승부의 장이겠네요.
세아: 그때는 진짜 모델끼리 싸우는 거죠.

제2차 회의 – STT 모델별 CER 결과 검증 및 비교 (확장 시나리오 버전)
세아: 지난 회의에서 세 모델 테스트해보기로 했잖아요? 결과 공유 좀 해주세요.
정현: 네, 전부 돌려봤어요. Whisper는 CER 4.8%, 클로바는 6.2%, 제미나이는 4.5%였습니다. 제미나이가 조금 더 안정적이더라고요.
용훈: 의외네. 제미나이가 제일 정확하다니… 근데 속도는요?
정현: 제미나이가 제일 빨랐어요. Whisper는 GPU 없으면 한참 걸렸고요.
수현: 그러면 결과 테이블에 처리 시간하고 인퍼런스 비용도 넣을게요. 나중에 비교할 때 편하니까요.
세아: 좋아요. 근데… 클로바가 한글 특화인데 제일 낮다는 게 좀 이상하네요.
용훈: 그건 API 구조 때문이에요. 문장을 중간에 잘라 버리더라고요. 문단 단위로 처리 못해서 그래요.
세아: 그래도 테스트 세팅은 같았잖아요. 그건 모델 문제가 아니라 우리가 세팅을 덜 맞춘 거 아닐까요?
용훈: 아니요, 그건 코드 구조상 한계예요. 세팅 잘못 아니에요.
정현: 두 분 잠시만요. 음성 길이도 차이가 있었어요.
클로바 쪽은 10분 이상 파일에 약간 끊김이 있었거든요.
수현: 어… 그러면 다음엔 파일 길이를 통일해볼까요? 제가 DB에서 필터로 길이 기준 맞춰볼게요.
세아: 네, 좋아요. 근데 발표용 그래프는 정확도랑 시간 둘 다 보이게 해야겠어요. 그게 더 설득력 있어요.
용훈: 아니 근데 세아님, 그 ‘설득력’이라는 게 수치로만 되는 건 아니잖아요.우리가 보여주려는 건 ‘모델이 실제 환경에서도 얼마나 버티냐’인데, 단순히 빠르고 정확하다고 해서 좋은 건 아니죠.예를 들어 회의 녹음처럼 잡음이 섞인 환경에서, 문장 맥락을 살리는 쪽이 진짜 유용한 모델이에요.그래서 저는 속도보다 문맥 일관성 지표 쪽을 강조하고 싶어요.
세아: 음… 그건 일리 있네요. 하지만, 지금은 시연용 자료라 심플해야 하거든요.너무 기술적으로 가면 일반 청중이 못 알아들어요.
그래프 하나로 ‘이게 더 좋다’ 보여줘야 돼요.
용훈: 네, 알겠습니다. 그래도 그 그래프 밑에 ‘문맥 보존율’ 같은 간단한 지표라도 넣자고요.그거 하나로 설득력 훨씬 올라갑니다.
정현: 좋아요. 그럼 제가 CER, 속도, 문맥 점수 세 축으로 비교해볼게요.시각화는 세아님 그래프에 바로 들어가게 만들겠습니다.
세아: 좋네요.
수현: 그럼 데이터는 세 가지 버전으로 저장할게요. 기본값, 노이즈 제거, 그리고 실시간 테스트.
용훈: 전처리에서 소음 제거 필터 한 번만 돌렸을 때랑 아닐 때 차이도 비교해볼게요.
정현: 그럼 케이스 A(원본), B(노이즈 제거) 두 세트로 나누는 걸로요.
세아: 좋아요. 그리고 문장 예시도 꼭 넣어 주세요. 숫자만 있으면 지루하니까요.
수현: 근데, 예시 문장에 그냥 결과만 넣는 거보다 하이라이트 표시로 바꾸면 어떨까요? 예를 들어, ‘제미나이: 정확히 인식’, ‘클로바: 단어 누락’, 이런 식으로 색 구분하면한눈에 모델별 특성이 보이니까 발표할 때 훨씬 깔끔할 것 같아요.저는 그걸 DB 뷰로 자동화할 수도 있어요.
그러면 매번 리포트 만들 필요도 없고요.
세아: 오, 그거 좋네요. 그렇게 가죠.
용훈: 문장 끝맺음 오류나 고유명사 인식도 따로 코멘트 넣겠습니다.
정현: 동일 타임스탬프 기준으로 차이만 보여주는 미니 리포트도 만들어볼게요.
세아: 좋아요. 근데… 다음 회의에서는 화자분리 테스트로 넘어가죠. 이건 정리 다 된 것 같아요.
수현: 네, DB도 화자별 구간 저장으로 바꿔둘게요.
용훈: Whisper는 diarization 모듈 내장돼 있으니까 그건 제가 돌려볼게요. 제미나이는 로직 따로 붙여야겠네요.
정현: 알겠습니다. 두 모델 다 테스트해보고 결과 정리하겠습니다.
세아: 화자 명칭은 숫자(speaker 1,2…)로 통일하고, 발표 때만 역할로 바꿔요.
수현: 역할은 별도 role 테이블로 관리하면 됩니다.
용훈: 그럼 오늘 합의 내용은 제가 정리해서 문서로 공유드릴게요.
정현: 네, 그 명세로 스크립트 업데이트하겠습니다.
세아: 좋아요. 다음은 화자분리 검증이네요. 다들 수고하셨습니다.
수현: 오늘 분위기 좀 뜨거웠네요. 하하… 그래도 진전은 있었어요!
용훈: 네, 뜨거워야 프로젝트가 굴러가죠.
세아: 그러네요. 그럼 마무리합시다.


제3차 회의 – 화자분리(Speaker Diarization) 성능 테스트 및 개선 (랜덤 순서 & 자연 대화 버전)
세아: 지난번에 모델 비교까지 끝났으니까, 오늘은 화자분리 테스트 결과를 공유받아볼게요.
정현: 네, 일단 Whisper는 기본 diarization 기능으로 돌려봤는데, 화자 세 명인데 네 명으로 인식하는 오류가 좀 있었어요.
DER이 약 21% 정도요. 제미나이는 diarization이 내장 안 돼서 pyannote.audio를 붙였더니 9%까지 줄었어요. 꽤 괜찮아요.
용훈: 오, pyannote 조합 괜찮네요. Whisper는 여전히 구간 겹침이 좀 많죠?
정현: 맞아요. 특히 짧은 맞장구나 중간에 끼어드는 말에서 구분을 잘 못 하더라고요.
수현: 그럼 화자 정보를 구간별로 나눠서 저장해야겠네요. speaker_id, start_time, end_time, text 이렇게요.
세아: 좋아요. 그럼 나중에 특정 화자만 모아서 요약하거나, 발언 패턴 분석도 가능하겠네요.
용훈: 어, 근데… 아, 이게 뭐였더라. 아, 그거요!pyannote에서 겹치는 화자 인식할 때 confidence 값이 따로 떨어지는 부분 있었잖아요.
그걸 활용하면 겹침 판단이 더 정밀해질 수도 있어요.예를 들어 두 명이 동시에 말하면, 확률값이 일정 비율 이하로 떨어지는 구간을 잡아서 “오버랩 구간”으로 태깅하면 됩니다.
정현: 오, 그거 괜찮네요. 그럼 pyannote 결과에 confidence threshold를 추가하는 거죠?
용훈: 맞아요. 아주 간단한 규칙으로 시작해볼 수 있을 것 같아요.
수현: 그래서 DB 구조도 살짝 바꿨어요. 겹침 여부를 저장하는 overlap_flag 필드를 추가했고요.
UI에서는 말풍선 위에 작은 겹침 아이콘이 표시되도록 해볼게요.
세아: 좋네요. 발표 때 “누가 언제 무슨 말을 했는지” 한눈에 보이게 색상으로 구분하면 좋겠어요.
용훈: 타임라인 스크러버랑 발화 하이라이트를 동기화하면 자연스러울 거예요. 말하는 순간 텍스트가 자동으로 따라가게요.
정현: 연속 발화 병합은 2초 이내면 같은 화자로 묶는 게 자연스럽더라고요.
그 기준값은 나중에 조정 가능하게 만들면 좋겠어요.
수현: 네, 그 임계값은 설정 테이블로 빼둘게요. 운영 중에도 바꿀 수 있게요.
세아: 그럼 데모에서는 숫자 화자명이 아니라 역할 기반으로 보여주는 게 낫겠어요.예를 들어 ‘기획’, ‘로직’, ‘테스트’, ‘백엔드’ 이렇게 바꾸면 직관적으로 이해되잖아요.다만, 실제 데이터 저장은 원본 번호(speaker 1, 2…)로 두고요.
용훈: 네, 그건 보여주는 단계에서만 매핑하겠습니다. 로직 쪽에서 변환 처리로 하면 되겠네요.
정현: DER 외에도, 사용자가 느끼는 자연스러움 같은 평가지표를 추가하면 좋겠어요. 그냥 숫자로는 안 잡히는 부분이 많거든요.
수현: 그럼 평가 태그 테이블 하나 더 만들게요. 주관식 메모도 가능하게요.
세아: 자, 그럼 이제 다음 단계는 요약과 액션아이템 자동 추출이죠.
이 부분은 지난번에 잠깐 얘기했었는데, 오늘부터 구체적으로 준비해봅시다.
용훈: diarization 결과를 transcript에 merge하는 방식으로 바꾸면 될 것 같아요. 말하자면 화자 정보를 기준으로 문장을 재배열하는 거죠.
정현: 병합 전후로 샘플 3건 정도 비교해서 리포트로 묶어오겠습니다. 오류가 어느 정도 줄었는지도 같이 볼게요.
수현: 그럼 액션아이템 추출 결과는 JSON으로 저장할게요. who, what, when 필드 형태로요.
세아: 사용자 입장에선 “해야 할 일”이 바로 보여야 하니까, 표시 순서는 ‘요약 → 액션아이템’ 순으로 합시다.
용훈: 문장에서 “~하겠습니다”, “~하기로 했습니다” 같은 패턴을 먼저 감지하고, 역할이랑 기한을 자동으로 붙이는 로직 만들게요.
정현: 정규식 초안은 제가 짜볼게요. 누락되는 문장은 수작업 라벨링으로 보완해가면서요.
수현: 그럼 role 필드랑 액션아이템을 조인하면 ‘누가 무엇을 언제’ 한눈에 볼 수 있겠네요.
세아: 완벽하네요.

제4차 회의 – 제미나이 기반 STT 확정 및 최종 발표 준비 (프로젝트 점검 & 리허설 전 회의)
세아: 자, 이제 거의 끝이네요. 오늘은 제미나이로 STT 모델을 확정하고, 발표용 데모랑 요약·액션아이템 자동추출 기능까지 최종 점검해볼게요.
정현: 네, 지난 회의에서 병합 로직까지 완성된 버전으로 테스트 돌려봤어요.
STT 정확도는 평균 CER 4.2%, 화자분리 DER은 7.3%로 꽤 안정적이었습니다.
용훈: 이제 모델 얘기하면 다들 감이 오죠. Whisper 시절엔 진짜 고생했는데, 제미나이로 오니까 확실히 안정됐어요.
속도도 약 1.7배 빨라졌고요.
수현: DB도 최종 구조 확정했습니다. 화자별·역할별 임베딩까지 저장 완료했고, 벡터 스토어랑 연동도 잘 돌아가요.
세아: 좋아요. 그럼 핵심인 “요약” 결과부터 볼까요?
정현: 문맥 기반 요약 정확도는 약 85% 나왔어요. 다만 “액션아이템이 명확하지 않은 문장”은 여전히 일부 누락되더라고요.
용훈: 그 부분은 프롬프트에서 역할 정보를 좀 더 강조하면 개선될 거예요. “기획자 세아가 결정한 내용”처럼 맥락을 주면 잘 잡습니다.
수현: 그래서 role 필드 기반 매칭 로직도 수정해놨어요. 이제 발화랑 역할이 직접 연결돼요.
세아: 좋네요. 근데 발표에서는 ‘결과값’보다 ‘사용자 입장에서 어떤 흐름으로 동작하느냐’가 더 중요하거든요.녹음 → STT → 요약 → 액션아이템 → 저장 → 검색, 이 일련의 과정이 “진짜 한 번에 된다”는 걸 보여줘야 해요.
용훈: 네, 그래서 데모 플로우를 그렇게 구성했어요. 화면 녹화 들어가면 음성 파일 업로드 → 실시간 인식 → 결과 창 표시 순으로 보여주고,각 화자별 텍스트가 실시간으로 올라오게끔 했습니다.
정현: 테스트도 영상 녹화 중에 해봤어요. 실제로 말 겹치는 구간에서도 자연스럽게 분리되더라고요.
수현: 대시보드도 다듬었어요. 상단에는 요약, 하단에는 액션 보드. 담당자별 정렬도 가능하고, 기한 임박 항목은 빨간 표시로 뜨게 했습니다.
세아: 완벽하네요. 이제 진짜 사용자 입장에서 봐도 ‘회의 끝나면 결과가 자동으로 정리되는 시스템’이에요.
용훈: 사실 이번 구조가 진짜 핵심이에요.
STT는 Gemini Pro API 기반으로, diarization 결과랑 merge한 transcript를 실시간으로 데이터베이스에 넣고,그걸 다시 벡터 스토어로 임베딩해서 검색 가능한 형태로 만드는 거죠.이게 돌아간다는 건 단순 전사 시스템이 아니라, 진짜 “AI 회의 분석 플랫폼”으로 올라왔다는 뜻이에요.
세아: 오… 발표 때 그 말 꼭 써야겠네요. ‘전사기에서 분석기로 진화했다’. 완전 좋은 문장이에요.
정현: 발표 카피가 벌써 나왔네요.
수현: 발표 자료에도 “데이터 흐름 다이어그램” 부분 업데이트할게요. STT→DB→벡터→검색 구조 흐름이 바로 보이게요.
세아: 그럼 액션아이템 쪽은요?
정현: 패턴 기반으로 추출 정확도 1차는 약 80%. 규칙 보정 후엔 87%까지 올라갔어요.
“하기로 했습니다”, “검토하겠습니다” 같은 문장은 잘 잡더라고요.
용훈: 패턴 추출 로직은 JSON 형태로 반환돼요. {who: “세아”, what: “결과 발표 준비”, when: “금요일”, status: “in_progress”} 이런 구조로요.
수현: 그 JSON은 자동으로 DB에 들어가고, 대시보드 액션 리스트에 표시돼요. 완료 처리하면 상태가 done으로 변경되고요.
세아: 좋아요. 그러면 발표 때 이걸 직접 보여줄 수 있겠네요. “한 문장 → 액션 생성” 흐름으로.
정현: 리허설은 내일 오후로 잡을까요?
용훈: 네, 오후 2시쯤이 좋겠어요. 제가 발표 시연 로직 정리해둘게요.
수현: 영상 녹화는 제가 맡을게요. 발표 장면용으로 짧게 편집해두면 좋을 것 같아요.
세아: 좋아요. 그럼 저는 발표 대본 정리해서 공유드릴게요.
오프닝은 제가 맡고, 기술 설명은 용훈님, 성능 비교는 정현님, 시스템 시연은 수현님 순으로 갈게요.
정현: 네, 완벽합니다. 리허설 때는 피드백 중심으로만 조정하면 되겠네요.
용훈: 발표용 UI 전환도 조금 더 부드럽게 다듬어두겠습니다.
수현: DB 백업은 이미 설정해뒀어요. 혹시 데모 중 오류 나도 바로 복구 가능합니다.
세아: 자, 오늘로 사실상 완성입니다.이 프로젝트는 “회의가 끝나면 AI가 자동으로 요약하고, 해야 할 일을 정리해주는 시스템”이라는 목표로 시작했죠.지금 우리는 그걸 실제로 구현했어요.
용훈: 네, 처음엔 단순 STT 실험이었는데, 여기까지 왔네요.
정현: 성능 지표도 만족스럽고, 결과물도 시연 가능한 수준이 됐어요.
수현: 전 이번 프로젝트가 진짜 팀워크 덕분에 완성됐다고 생각해요.
세아: 그러네요. 다들 고생 많았어요.다음은 발표 무대에서 멋지게 마무리합시다.
