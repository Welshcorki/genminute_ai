# 회의록 챗봇 테스트 질문 리스트

> **챗봇 검색 방식**: Similarity Retriever (의미 기반 유사도 검색)
> **검색 대상**: meeting_chunks (대화 내용) 3개 + meeting_subtopic (주제별 요약) 3개
> **답변 생성**: Gemini 2.5 Flash (검색된 컨텍스트 기반)

---

## 기본 정보 조회 질문 (1-5)

### 1. 총 몇 개의 회의가 진행되었나요?

**예상 검색 방식:**
- 검색 키워드: "회의", "진행"
- 주요 검색 대상: subtopic (각 회의 요약에 "제1차", "제2차" 등 포함)
- 예상 성공률: ⚠️ **중간** - 메타데이터 집계가 필요한 질문이라 검색된 문서만으로는 부족할 수 있음
- 개선 방법: 메타데이터 기반 집계 기능 필요

---

### 2. 1차 회의의 주제는 무엇인가요?

**예상 검색 방식:**
- 검색 키워드: "1차 회의", "주제"
- 주요 검색 대상: subtopic (회의 요약에 제목 포함) + chunks (회의 시작 부분)
- 예상 성공률: ✅ **높음** - "제1차 회의 – STT 모델 선정 및 테스트 기준 설정" 찾을 가능성 높음

---

### 3. 제4차 회의에서 논의한 주요 내용을 알려주세요.

**예상 검색 방식:**
- 검색 키워드: "4차 회의", "논의", "주요 내용"
- 주요 검색 대상: subtopic (4차 회의 요약)
- 예상 성공률: ✅ **높음** - subtopic에 회의 주제와 핵심 내용 포함

---

### 4. 회의에 참석한 사람들은 누구누구인가요?

**예상 검색 방식:**
- 검색 키워드: "참석", "사람"
- 주요 검색 대상: chunks (대화 내용에 화자 이름 포함)
- 예상 성공률: ✅ **높음** - 대화에 "세아", "정현", "용훈", "수현" 반복 등장
- 참고: 메타데이터에 participant 필드가 있다면 더 정확

---

### 5. 세아가 담당한 역할이나 업무는 무엇인가요?

**예상 검색 방식:**
- 검색 키워드: "세아", "담당", "역할", "업무"
- 주요 검색 대상: chunks (세아의 발언 내용) + subtopic
- 예상 성공률: ✅ **높음** - "세아: 그럼 저는 발표 대본 정리해서..." 등 액션 아이템 많음

---

## 기술적 내용 질문 (6-10)

### 6. 1차 회의에서 후보로 올라온 STT 모델은 무엇무엇인가요?

**예상 검색 방식:**
- 검색 키워드: "1차 회의", "STT 모델", "후보"
- 주요 검색 대상: chunks (1차 회의 초반 대화)
- 예상 성공률: ✅ **높음** - "Whisper, 클로바스피치, 제미나이" 명시됨

---

### 7. 2차 회의에서 제미나이의 CER은 몇 퍼센트였나요?

**예상 검색 방식:**
- 검색 키워드: "2차 회의", "제미나이", "CER", "퍼센트"
- 주요 검색 대상: chunks (정현의 발언에 정확한 수치 포함)
- 예상 성공률: ✅ **높음** - "제미나이는 4.5%였습니다" 명확한 수치

---

### 8. Whisper 모델의 장점과 단점은 무엇인가요?

**예상 검색 방식:**
- 검색 키워드: "Whisper", "장점", "단점"
- 주요 검색 대상: chunks (1차, 2차 회의의 Whisper 관련 대화)
- 예상 성공률: ✅ **높음** - "잡음엔 강한 편이지만 속도가 느리고" 등 명시됨

---

### 9. 화자분리 테스트에서 사용된 pyannote.audio의 DER 성능은 어땠나요?

**예상 검색 방식:**
- 검색 키워드: "화자분리", "pyannote", "DER", "성능"
- 주요 검색 대상: chunks (3차 회의 정현 발언)
- 예상 성공률: ✅ **높음** - "pyannote.audio를 붙였더니 9%까지 줄었어요" 명확

---

### 10. 최종적으로 선택된 STT 모델은 무엇이고 그 이유는 무엇인가요?

**예상 검색 방식:**
- 검색 키워드: "최종", "선택", "STT 모델", "이유"
- 주요 검색 대상: chunks (4차 회의) + subtopic
- 예상 성공률: ✅ **높음** - "제미나이로 STT 모델을 확정", "속도도 약 1.7배 빨라졌고요"

---

## 결정 사항 및 액션 아이템 질문 (11-15)

### 11. 용훈이 맡기로 한 작업은 무엇무엇인가요?

**예상 검색 방식:**
- 검색 키워드: "용훈", "맡기로", "작업"
- 주요 검색 대상: chunks (용훈의 "~할게요", "~하겠습니다" 발언)
- 예상 성공률: ⚠️ **중간** - 여러 회의에 걸쳐 분산되어 있어 3개 검색으로는 모두 못 가져올 수 있음

---

### 12. 1차 회의에서 테스트 데이터를 어떻게 구분하기로 했나요?

**예상 검색 방식:**
- 검색 키워드: "1차 회의", "테스트 데이터", "구분"
- 주요 검색 대상: chunks (1차 회의 초반 대화)
- 예상 성공률: ✅ **높음** - "회의형, 뉴스형, 일상대화형으로 나누면" 명확

---

### 13. 수현이 DB 스키마에 추가한 필드들은 무엇인가요?

**예상 검색 방식:**
- 검색 키워드: "수현", "DB 스키마", "필드", "추가"
- 주요 검색 대상: chunks (수현의 발언 중 DB 관련 내용)
- 예상 성공률: ⚠️ **중간** - 여러 회의에 걸쳐 필드가 추가되어 부분적으로만 답변 가능

---

### 14. 2차 회의에서 그래프에 표시하기로 한 지표는 무엇인가요?

**예상 검색 방식:**
- 검색 키워드: "2차 회의", "그래프", "지표"
- 주요 검색 대상: chunks (2차 회의 후반부 논의)
- 예상 성공률: ✅ **높음** - "CER, 속도, 문맥 점수 세 축으로 비교해볼게요" 명확

---

### 15. 발표 준비에서 각 팀원이 맡은 역할을 알려주세요.

**예상 검색 방식:**
- 검색 키워드: "발표 준비", "팀원", "역할"
- 주요 검색 대상: chunks (4차 회의 후반부 역할 분담)
- 예상 성공률: ✅ **높음** - "오프닝은 제가 맡고, 기술 설명은 용훈님..." 명확

---

## 성능 및 비교 질문 (16-18)

### 16. 2차 회의에서 Whisper, 클로바, 제미나이의 CER을 각각 비교해주세요.

**예상 검색 방식:**
- 검색 키워드: "2차 회의", "Whisper", "클로바", "제미나이", "CER"
- 주요 검색 대상: chunks (정현의 결과 발표)
- 예상 성공률: ✅ **높음** - "Whisper는 CER 4.8%, 클로바는 6.2%, 제미나이는 4.5%" 명확

---

### 17. 제미나이로 변경한 후 속도는 얼마나 빨라졌나요?

**예상 검색 방식:**
- 검색 키워드: "제미나이", "속도", "빨라졌"
- 주요 검색 대상: chunks (4차 회의 용훈 발언)
- 예상 성공률: ✅ **높음** - "속도도 약 1.7배 빨라졌고요" 명확

---

### 18. 액션아이템 추출 정확도는 규칙 보정 전후로 각각 몇 퍼센트였나요?

**예상 검색 방식:**
- 검색 키워드: "액션아이템", "정확도", "규칙 보정"
- 주요 검색 대상: chunks (4차 회의 정현 발언)
- 예상 성공률: ✅ **높음** - "1차는 약 80%. 규칙 보정 후엔 87%" 명확

---

## 복합 질문 (19-20)

### 19. 화자분리 기능 개선을 위해 3차 회의에서 논의된 방법은 무엇인가요?

**예상 검색 방식:**
- 검색 키워드: "화자분리", "개선", "3차 회의", "방법"
- 주요 검색 대상: chunks (3차 회의 중반부) + subtopic
- 예상 성공률: ✅ **높음** - "confidence 값", "오버랩 구간 태깅", "연속 발화 병합" 등 여러 방법 논의됨

---

### 20. 프로젝트의 최종 목표는 무엇이고, 4차 회의 시점에서 달성했나요?

**예상 검색 방식:**
- 검색 키워드: "최종 목표", "달성", "4차 회의"
- 주요 검색 대상: chunks (4차 회의 세아 발언) + subtopic
- 예상 성공률: ✅ **높음** - "회의가 끝나면 AI가 자동으로 요약하고, 해야 할 일을 정리해주는 시스템", "지금 우리는 그걸 실제로 구현했어요"

---

## 추가 테스트용 질문 (난이도 높음)

### 21. 클로바의 CER이 예상보다 낮게 나온 이유는 무엇인가요?

**예상 검색 방식:**
- 검색 키워드: "클로바", "CER", "낮게", "이유"
- 주요 검색 대상: chunks (2차 회의 논쟁 부분)
- 예상 성공률: ✅ **높음** - "문장을 중간에 잘라 버리더라고요", "문단 단위로 처리 못해서"

---

### 22. 정현과 용훈이 의견이 달랐던 부분은 무엇인가요?

**예상 검색 방식:**
- 검색 키워드: "정현", "용훈", "의견"
- 주요 검색 대상: chunks (2차 회의 논의 부분)
- 예상 성공률: ⚠️ **중간** - 구체적인 대립 장면보다는 관점 차이가 대화에 섞여있음
- 예상 답변: 발표 그래프 구성(세아-용훈), 세팅 문제 해석(용훈-정현) 등

---

### 23. DB 구조가 회의마다 어떻게 개선되었나요?

**예상 검색 방식:**
- 검색 키워드: "DB 구조", "개선", "회의"
- 주요 검색 대상: chunks (수현의 발언) + subtopic
- 예상 성공률: ⚠️ **중간** - 시계열 변화를 추적해야 하는데, 3개 검색으로는 모든 변경사항을 못 가져올 수 있음
- 예상 답변: 부분적 답변 (환경 필드, overlap_flag, role 테이블 등 일부만 언급)

---

### 24. 발표 데모 플로우는 어떻게 구성되었나요?

**예상 검색 방식:**
- 검색 키워드: "발표", "데모", "플로우", "구성"
- 주요 검색 대상: chunks (4차 회의 용훈 발언)
- 예상 성공률: ✅ **높음** - "음성 파일 업로드 → 실시간 인식 → 결과 창 표시" 명확히 설명됨

---

### 25. 프로젝트가 "전사기에서 분석기로 진화했다"는 표현의 의미는 무엇인가요?

**예상 검색 방식:**
- 검색 키워드: "전사기", "분석기", "진화"
- 주요 검색 대상: chunks (4차 회의 용훈 발언)
- 예상 성공률: ✅ **높음** - 용훈이 "단순 전사 시스템이 아니라, 진짜 AI 회의 분석 플랫폼으로 올라왔다" 명확히 설명

---

## 예상 성공률 요약

- ✅ **높음** (검색 & 답변 성공 예상): 18개 질문
- ⚠️ **중간** (부분 답변 또는 누락 가능): 7개 질문
- ❌ **낮음** (답변 실패 가능): 0개 질문

### 중간 성공률 질문의 공통점
1. **집계 필요**: 총 회의 개수 등 메타데이터 기반 집계
2. **여러 회의 걸침**: 용훈의 모든 작업, DB 필드 변화 추적
3. **복합 정보**: 의견 차이, 시계열 변화 등

### 개선 방안
- 메타데이터 쿼리 기능 추가 (meeting_id 집계)
- 검색 개수 증가 (chunks 3개 → 5개)
- LangGraph Agent 구현 (의도 분석 → 적절한 검색 전략 선택)
